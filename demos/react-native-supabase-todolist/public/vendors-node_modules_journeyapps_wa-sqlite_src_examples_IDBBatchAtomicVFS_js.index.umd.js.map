{"version":3,"file":"vendors-node_modules_journeyapps_wa-sqlite_src_examples_IDBBatchAtomicVFS_js.index.umd.js","mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;AC3KA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;AC52BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;AC3PA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","sources":["webpack://sdk_web/../../node_modules/@journeyapps/wa-sqlite/src/VFS.js","webpack://sdk_web/../../node_modules/@journeyapps/wa-sqlite/src/examples/IDBBatchAtomicVFS.js","webpack://sdk_web/../../node_modules/@journeyapps/wa-sqlite/src/examples/IDBContext.js","webpack://sdk_web/../../node_modules/@journeyapps/wa-sqlite/src/examples/WebLocks.js"],"sourcesContent":["// Copyright 2022 Roy T. Hashimoto. All Rights Reserved.\nimport * as VFS from './sqlite-constants.js';\nexport * from './sqlite-constants.js';\n\n// Base class for a VFS.\nexport class Base {\n  mxPathName = 64;\n\n  /**\n   * @param {number} fileId \n   * @returns {number}\n   */\n  xClose(fileId) {\n    return VFS.SQLITE_IOERR;\n  }\n\n  /**\n   * @param {number} fileId \n   * @param {Uint8Array} pData \n   * @param {number} iOffset\n   * @returns {number}\n   */\n  xRead(fileId, pData, iOffset) {\n    return VFS.SQLITE_IOERR;\n  }\n\n  /**\n   * @param {number} fileId \n   * @param {Uint8Array} pData \n   * @param {number} iOffset\n   * @returns {number}\n   */\n  xWrite(fileId, pData, iOffset) {\n    return VFS.SQLITE_IOERR;\n  }\n\n  /**\n   * @param {number} fileId \n   * @param {number} iSize \n   * @returns {number}\n   */\n  xTruncate(fileId, iSize) {\n    return VFS.SQLITE_IOERR;\n  }\n\n  /**\n   * @param {number} fileId \n   * @param {*} flags \n   * @returns {number}\n   */\n  xSync(fileId, flags) {\n    return VFS.SQLITE_OK;\n  }\n\n  /**\n   * @param {number} fileId \n   * @param {DataView} pSize64 \n   * @returns {number}\n   */\n  xFileSize(fileId, pSize64) {\n    return VFS.SQLITE_IOERR;\n  }\n\n  /**\n   * @param {number} fileId \n   * @param {number} flags \n   * @returns {number}\n   */\n  xLock(fileId, flags) {\n    return VFS.SQLITE_OK;\n  }\n\n  /**\n   * @param {number} fileId \n   * @param {number} flags \n   * @returns {number}\n   */\n  xUnlock(fileId, flags) {\n    return VFS.SQLITE_OK;\n  }\n\n  /**\n   * @param {number} fileId \n   * @param {DataView} pResOut \n   * @returns {number}\n   */\n  xCheckReservedLock(fileId, pResOut) {\n    pResOut.setInt32(0, 0, true);\n    return VFS.SQLITE_OK;\n  }\n\n  /**\n   * @param {number} fileId \n   * @param {number} op \n   * @param {DataView} pArg \n   * @returns {number}\n   */\n  xFileControl(fileId, op, pArg) {\n    return VFS.SQLITE_NOTFOUND;\n  }\n\n  /**\n   * @param {number} fileId \n   * @returns {number}\n   */\n  xSectorSize(fileId) {\n    return 512;\n  }\n\n  /**\n   * @param {number} fileId \n   * @returns {number}\n   */\n  xDeviceCharacteristics(fileId) {\n    return 0;\n  }\n\n  /**\n   * @param {string?} name \n   * @param {number} fileId \n   * @param {number} flags \n   * @param {DataView} pOutFlags \n   * @returns {number}\n   */\n  xOpen(name, fileId, flags, pOutFlags) {\n    return VFS.SQLITE_CANTOPEN;\n  }\n\n  /**\n   * @param {string} name \n   * @param {number} syncDir \n   * @returns {number}\n   */\n  xDelete(name, syncDir) {\n    return VFS.SQLITE_IOERR;\n  }\n\n  /**\n   * @param {string} name \n   * @param {number} flags \n   * @param {DataView} pResOut \n   * @returns {number}\n   */\n  xAccess(name, flags, pResOut) {\n    return VFS.SQLITE_IOERR;\n  }\n\n  /**\n   * Handle asynchronous operation. This implementation will be overriden on\n   * registration by an Asyncify build.\n   * @param {function(): Promise<number>} f \n   * @returns {number}\n   */\n  handleAsync(f) {\n    // This default implementation deliberately does not match the\n    // declared signature. It will be used in testing VFS classes\n    // separately from SQLite. This will work acceptably for methods\n    // that simply return the handleAsync() result without using it.\n    // @ts-ignore\n    return f();\n  }\n}\n\nexport const FILE_TYPE_MASK = [\n  VFS.SQLITE_OPEN_MAIN_DB,\n  VFS.SQLITE_OPEN_MAIN_JOURNAL,\n  VFS.SQLITE_OPEN_TEMP_DB,\n  VFS.SQLITE_OPEN_TEMP_JOURNAL,\n  VFS.SQLITE_OPEN_TRANSIENT_DB,\n  VFS.SQLITE_OPEN_SUBJOURNAL,\n  VFS.SQLITE_OPEN_SUPER_JOURNAL\n].reduce((mask, element) => mask | element);","// Copyright 2022 Roy T. Hashimoto. All Rights Reserved.\nimport * as VFS from '../VFS.js';\nimport { WebLocksExclusive as WebLocks } from './WebLocks.js';\nimport { IDBContext } from './IDBContext.js';\n\nconst SECTOR_SIZE = 512;\nconst MAX_TASK_MILLIS = 3000;\n\n/**\n * @typedef VFSOptions\n * @property {\"default\"|\"strict\"|\"relaxed\"} [durability]\n * @property {\"deferred\"|\"manual\"} [purge]\n * @property {number} [purgeAtLeast]\n */\n\n/** @type {VFSOptions} */\nconst DEFAULT_OPTIONS = {\n  durability: \"default\",\n  purge: \"deferred\",\n  purgeAtLeast: 16\n};\n\nfunction log(...args) {\n  // console.debug(...args);\n}\n\n/**\n * @typedef FileBlock IndexedDB object with key [path, offset, version]\n * @property {string} path\n * @property {number} offset negative of position in file\n * @property {number} version\n * @property {Uint8Array} data\n *\n * @property {number} [fileSize] Only present on block 0\n*/\n\n/**\n * @typedef OpenedFileEntry\n * @property {string} path\n * @property {number} flags\n * @property {FileBlock} block0\n * @property {boolean} isMetadataChanged\n * @property {WebLocks} locks\n * \n * @property {Set<number>} [changedPages]\n * @property {boolean} [overwrite]\n */\n\n// This sample VFS stores optionally versioned writes to IndexedDB, which\n// it uses with the SQLite xFileControl() batch atomic write feature.\nexport class IDBBatchAtomicVFS extends VFS.Base {\n  #options;\n  /** @type {Map<number, OpenedFileEntry>} */ #mapIdToFile = new Map();\n\n  /** @type {IDBContext} */ #idb;\n  /** @type {Set<string>} */ #pendingPurges = new Set();\n\n  #taskTimestamp = performance.now();\n  #pendingAsync = new Set();\n\n  // Asyncify can grow WebAssembly memory during an asynchronous call.\n  // If this happens, then any array buffer arguments will be detached.\n  // The workaround is when finding a detached buffer, set this handler\n  // function to process the new buffer outside handlerAsync().\n  #growthHandler = null;\n\n  constructor(idbDatabaseName = 'wa-sqlite', options = DEFAULT_OPTIONS) {\n    super();\n    this.name = idbDatabaseName;\n    this.#options = Object.assign({}, DEFAULT_OPTIONS, options);\n    this.#idb = new IDBContext(openDatabase(idbDatabaseName), {\n      durability: this.#options.durability\n    });\n  }\n\n  async close() {\n    for (const fileId of this.#mapIdToFile.keys()) {\n      await this.xClose(fileId);\n    }\n\n    await this.#idb?.close();\n    this.#idb = null;\n  }\n\n  /**\n   * @param {string?} name \n   * @param {number} fileId \n   * @param {number} flags \n   * @param {DataView} pOutFlags \n   * @returns {number}\n   */\n  xOpen(name, fileId, flags, pOutFlags) {\n    const result = this.handleAsync(async () => {\n      if (name === null) name = `null_${fileId}`;\n      log(`xOpen ${name} 0x${fileId.toString(16)} 0x${flags.toString(16)}`);\n\n      try {\n        // Filenames can be URLs, possibly with query parameters.\n        const url = new URL(name, 'http://localhost/');\n        /** @type {OpenedFileEntry} */ const file = {\n          path: url.pathname,\n          flags,\n          block0: null,\n          isMetadataChanged: true,\n          locks: new WebLocks(url.pathname)\n        };\n        this.#mapIdToFile.set(fileId, file);\n\n        // Read the first block, which also contains the file metadata.\n        await this.#idb.run('readwrite', async ({blocks}) => {\n          file.block0 = await blocks.get(this.#bound(file, 0));\n          if (!file.block0) {\n            if (flags & VFS.SQLITE_OPEN_CREATE) {\n              file.block0 = {\n                path: file.path,\n                offset: 0,\n                version: 0,\n                data: new Uint8Array(0),\n                fileSize: 0\n              };\n              blocks.put(file.block0);\n            } else {\n              throw new Error(`file not found: ${file.path}`);\n            }\n          }\n        });\n\n        // @ts-ignore\n        if (pOutFlags.buffer.detached || !pOutFlags.buffer.byteLength) {\n          pOutFlags = new DataView(new ArrayBuffer(4));\n          this.#growthHandler = (pOutFlagsNew) => {\n            pOutFlagsNew.setInt32(0, pOutFlags.getInt32(0, true), true);\n          };\n        }\n        pOutFlags.setInt32(0, flags & VFS.SQLITE_OPEN_READONLY, true);\n        return VFS.SQLITE_OK;\n      } catch (e) {\n        console.error(e);\n        return VFS.SQLITE_CANTOPEN;\n      }\n    });\n\n    this.#growthHandler?.(pOutFlags);\n    this.#growthHandler = null;\n    return result;\n  }\n\n  /**\n   * @param {number} fileId \n   * @returns {number}\n   */\n  xClose(fileId) {\n    return this.handleAsync(async () => {\n      try {\n        const file = this.#mapIdToFile.get(fileId);\n        if (file) {\n          log(`xClose ${file.path}`);\n\n          this.#mapIdToFile.delete(fileId);\n          if (file.flags & VFS.SQLITE_OPEN_DELETEONCLOSE) {\n            this.#idb.run('readwrite', ({blocks}) => {\n              blocks.delete(IDBKeyRange.bound([file.path], [file.path, []]));\n            });\n          }\n        }\n        return VFS.SQLITE_OK;\n      } catch (e) {\n        console.error(e);\n        return VFS.SQLITE_IOERR;\n      }\n    });\n  }\n\n  /**\n   * @param {number} fileId \n   * @param {Uint8Array} pData \n   * @param {number} iOffset\n   * @returns {number}\n   */\n  xRead(fileId, pData, iOffset) {\n    const byteLength = pData.byteLength;\n    const result = this.handleAsync(async () => {\n      const file = this.#mapIdToFile.get(fileId);\n      log(`xRead ${file.path} ${pData.byteLength} ${iOffset}`);\n\n      try {\n        // Read as many blocks as necessary to satisfy the read request.\n        // Usually a read fits within a single write but there is at least\n        // one case - rollback after journal spill - where reads cross\n        // write boundaries so we have to allow for that.\n        const result = await this.#idb.run('readonly', async ({blocks}) => {\n          // @ts-ignore\n          if (pData.buffer.detached || !pData.buffer.byteLength) {\n            // WebAssembly memory has grown, invalidating our buffer. Use\n            // a temporary buffer and copy after this asynchronous call\n            // completes.\n            pData = new Uint8Array(byteLength);\n            this.#growthHandler = (pDataNew) => pDataNew.set(pData);\n          }\n\n          let pDataOffset = 0;\n          while (pDataOffset < pData.byteLength) {\n            // Fetch the IndexedDB block for this file location.\n            const fileOffset = iOffset + pDataOffset;\n            /** @type {FileBlock} */\n            const block = fileOffset < file.block0.data.byteLength ?\n              file.block0 :\n              await blocks.get(this.#bound(file, -fileOffset));\n\n            if (!block || block.data.byteLength - block.offset <= fileOffset) {\n              pData.fill(0, pDataOffset);\n              return VFS.SQLITE_IOERR_SHORT_READ;\n            }\n\n            const buffer = pData.subarray(pDataOffset);\n            const blockOffset = fileOffset + block.offset;\n            const nBytesToCopy = Math.min(\n              Math.max(block.data.byteLength - blockOffset, 0), // source bytes\n              buffer.byteLength);                               // destination bytes\n            buffer.set(block.data.subarray(blockOffset, blockOffset + nBytesToCopy));\n            pDataOffset += nBytesToCopy;\n          }\n          return VFS.SQLITE_OK;\n        });\n        return result;\n      } catch (e) {\n        console.error(e);\n        return VFS.SQLITE_IOERR;\n      }\n    });\n\n    this.#growthHandler?.(pData);\n    this.#growthHandler = null;\n    return result;\n  }\n\n  /**\n   * @param {number} fileId \n   * @param {Uint8Array} pData \n   * @param {number} iOffset\n   * @returns {number}\n   */\n  xWrite(fileId, pData, iOffset) {\n    // Handle asynchronously every MAX_TASK_MILLIS milliseconds. This is\n    // tricky because Asyncify calls asynchronous methods twice: once\n    // to initiate the call and unwinds the stack, then rewinds the\n    // stack and calls again to retrieve the completed result.\n    const rewound = this.#pendingAsync.has(fileId);\n    if (rewound || performance.now() - this.#taskTimestamp > MAX_TASK_MILLIS) {\n      const result = this.handleAsync(async () => {\n        if (this.handleAsync !== super.handleAsync) {\n          this.#pendingAsync.add(fileId);\n        }\n        await new Promise(resolve => setTimeout(resolve));\n\n        const result = this.#xWriteHelper(fileId, pData.slice(), iOffset);\n        this.#taskTimestamp = performance.now();\n        return result;\n      });\n\n      if (rewound) this.#pendingAsync.delete(fileId);\n      return result;\n    }\n    return this.#xWriteHelper(fileId, pData, iOffset);\n  }\n\n  /**\n   * @param {number} fileId \n   * @param {Uint8Array} pData \n   * @param {number} iOffset\n   * @returns {number}\n   */\n  #xWriteHelper(fileId, pData, iOffset) {\n    const file = this.#mapIdToFile.get(fileId);\n    log(`xWrite ${file.path} ${pData.byteLength} ${iOffset}`);\n\n    try {\n      // Update file size if appending.\n      const prevFileSize = file.block0.fileSize;\n      if (file.block0.fileSize < iOffset + pData.byteLength) {\n        file.block0.fileSize = iOffset + pData.byteLength;\n        file.isMetadataChanged = true;\n      }\n\n      // Convert the write directly into an IndexedDB object. Our assumption\n      // is that SQLite will only overwrite data with an xWrite of the same\n      // offset and size unless the database page size changes, except when\n      // changing database page size which is handled by #reblockIfNeeded().\n      const block = iOffset === 0 ? file.block0 : {\n        path: file.path,\n        offset: -iOffset,\n        version: file.block0.version,\n        data: null\n      };\n      block.data = pData.slice();\n\n      if (file.changedPages) {\n        // This write is part of a batch atomic write. All writes in the\n        // batch have a new version, so update the changed list to allow\n        // old versions to be eventually deleted.\n        if (prevFileSize === file.block0.fileSize) {\n          file.changedPages.add(-iOffset);\n        }\n\n        // Defer writing block 0 to IndexedDB until batch commit.\n        if (iOffset !== 0) {\n          this.#idb.run('readwrite', ({blocks}) => blocks.put(block));\n        }\n      } else {\n        // Not a batch atomic write so write through.\n        this.#idb.run('readwrite', ({blocks}) => blocks.put(block));\n      }\n\n      // Clear dirty flag if page 0 was written.\n      file.isMetadataChanged = iOffset === 0 ? false : file.isMetadataChanged;\n      return VFS.SQLITE_OK;\n    } catch (e) {\n      console.error(e);\n      return VFS.SQLITE_IOERR;\n    }\n  }\n\n  /**\n   * @param {number} fileId \n   * @param {number} iSize \n   * @returns {number}\n   */\n  xTruncate(fileId, iSize) {\n    const file = this.#mapIdToFile.get(fileId);\n    log(`xTruncate ${file.path} ${iSize}`);\n\n    try {\n      Object.assign(file.block0, {\n        fileSize: iSize,\n        data: file.block0.data.slice(0, iSize)\n      });\n\n      // Delete all blocks beyond the file size and update metadata.\n      // This is never called within a transaction.\n      const block0 = Object.assign({}, file.block0);\n      this.#idb.run('readwrite', ({blocks})=> {\n        blocks.delete(this.#bound(file, -Infinity, -iSize));\n        blocks.put(block0);\n      });\n      return VFS.SQLITE_OK;\n    } catch (e) {\n      console.error(e);\n      return VFS.SQLITE_IOERR;\n    }\n  }\n\n  /**\n   * @param {number} fileId \n   * @param {number} flags \n   * @returns {number}\n   */\n  xSync(fileId, flags) {\n    // Skip IndexedDB sync if durability is relaxed and the last\n    // sync was recent enough.\n    const rewound = this.#pendingAsync.has(fileId);\n    if (rewound || this.#options.durability !== 'relaxed' ||\n        performance.now() - this.#taskTimestamp > MAX_TASK_MILLIS) {\n      const result = this.handleAsync(async () => {\n        if (this.handleAsync !== super.handleAsync) {\n          this.#pendingAsync.add(fileId);\n        }\n\n        const result = await this.#xSyncHelper(fileId, flags);\n        this.#taskTimestamp = performance.now();\n        return result;\n      });\n\n      if (rewound) this.#pendingAsync.delete(fileId);\n      return result;\n    }\n\n    const file = this.#mapIdToFile.get(fileId);\n    log(`xSync ${file.path} ${flags}`);\n    return VFS.SQLITE_OK;\n  }\n\n  /**\n   * @param {number} fileId \n   * @param {number} flags \n   * @returns {Promise<number>}\n   */\n  async #xSyncHelper(fileId, flags) {\n    const file = this.#mapIdToFile.get(fileId);\n    log(`xSync ${file.path} ${flags}`);\n    try {\n      if (file.isMetadataChanged) {\n        // Metadata has changed so write block 0 to IndexedDB.\n        this.#idb.run('readwrite', async ({blocks}) => {\n          await blocks.put(file.block0);\n        }); \n        file.isMetadataChanged = false;\n      }\n      await this.#idb.sync();\n    } catch (e) {\n      console.error(e);\n      return VFS.SQLITE_IOERR;\n    }\n    return VFS.SQLITE_OK;\n  }\n\n  /**\n   * @param {number} fileId \n   * @param {DataView} pSize64 \n   * @returns {number}\n   */\n  xFileSize(fileId, pSize64) {\n    const file = this.#mapIdToFile.get(fileId);\n    log(`xFileSize ${file.path}`);\n\n    pSize64.setBigInt64(0, BigInt(file.block0.fileSize), true)\n    return VFS.SQLITE_OK;\n  }\n\n  /**\n   * @param {number} fileId \n   * @param {number} flags \n   * @returns {number}\n   */\n  xLock(fileId, flags) {\n    return this.handleAsync(async () => {\n      const file = this.#mapIdToFile.get(fileId);\n      log(`xLock ${file.path} ${flags}`);\n\n      try {\n        // Acquire the lock.\n        const result = await file.locks.lock(flags);\n        if (result === VFS.SQLITE_OK && file.locks.state === VFS.SQLITE_LOCK_SHARED) {\n          // Update block 0 in case another connection changed it.\n          file.block0 = await this.#idb.run('readonly', ({blocks}) => {\n            return blocks.get(this.#bound(file, 0));\n          });\n        }\n        return result;\n      } catch (e) {\n        console.error(e);\n        return VFS.SQLITE_IOERR;\n      }\n    });\n  }\n\n  /**\n   * @param {number} fileId \n   * @param {number} flags \n   * @returns {number}\n   */\n  xUnlock(fileId, flags) {\n    return this.handleAsync(async () => {\n      const file = this.#mapIdToFile.get(fileId);\n      log(`xUnlock ${file.path} ${flags}`);\n      \n      try {\n        return file.locks.unlock(flags);\n      } catch(e) {\n        console.error(e);\n        return VFS.SQLITE_IOERR;\n      }\n    });\n  }\n\n  /**\n   * @param {number} fileId \n   * @param {DataView} pResOut \n   * @returns {number}\n   */\n  xCheckReservedLock(fileId, pResOut) {\n    const result = this.handleAsync(async () => {\n      const file = this.#mapIdToFile.get(fileId);\n      log(`xCheckReservedLock ${file.path}`);\n\n      const isReserved = await file.locks.isSomewhereReserved();\n      function setOutput(pResOut) {\n      };\n\n      // @ts-ignore\n      if (pResOut.buffer.detached || !pResOut.buffer.byteLength) {\n        pResOut = new DataView(new ArrayBuffer(4));\n        this.#growthHandler = (pResOutNew) => {\n          pResOutNew.setInt32(0, pResOut.getInt32(0, true), true);\n        };\n      }\n      pResOut.setInt32(0, isReserved ? 1 : 0, true);\n      return VFS.SQLITE_OK;\n    });\n\n    this.#growthHandler?.(pResOut);\n    this.#growthHandler = null;\n    return result;\n  }\n\n  /**\n   * @param {number} fileId \n   * @returns {number}\n   */\n  xSectorSize(fileId) {\n    log('xSectorSize');\n    return SECTOR_SIZE;\n  }\n\n  /**\n   * @param {number} fileId \n   * @returns {number}\n   */\n  xDeviceCharacteristics(fileId) {\n    log('xDeviceCharacteristics');\n    return VFS.SQLITE_IOCAP_BATCH_ATOMIC |\n           VFS.SQLITE_IOCAP_SAFE_APPEND |\n           VFS.SQLITE_IOCAP_SEQUENTIAL |\n           VFS.SQLITE_IOCAP_UNDELETABLE_WHEN_OPEN;\n  }\n\n  /**\n   * @param {number} fileId \n   * @param {number} op \n   * @param {DataView} pArg \n   * @returns {number}\n   */\n  xFileControl(fileId, op, pArg) {\n    const file = this.#mapIdToFile.get(fileId);\n    log(`xFileControl ${file.path} ${op}`);\n\n    switch (op) {\n      case 11: //SQLITE_FCNTL_OVERWRITE\n        // This called on VACUUM. Set a flag so we know whether to check\n        // later if the page size changed.\n        file.overwrite = true;\n        return VFS.SQLITE_OK;\n\n      case 21: // SQLITE_FCNTL_SYNC\n        // This is called at the end of each database transaction, whether\n        // it is batch atomic or not. Handle page size changes here.\n        if (file.overwrite) {\n          // As an optimization we only check for and handle a page file\n          // changes if we know a VACUUM has been done because handleAsync()\n          // has to unwind and rewind the stack. We must be sure to follow\n          // the same conditional path in both calls.\n          try {\n            return this.handleAsync(async () => {\n              await this.#reblockIfNeeded(file);\n              return VFS.SQLITE_OK;\n            });\n          } catch (e) {\n            console.error(e);\n            return VFS.SQLITE_IOERR;\n          }\n        }\n\n        if (file.isMetadataChanged) {\n          // Metadata has changed so write block 0 to IndexedDB.\n          try {\n            this.#idb.run('readwrite', async ({blocks}) => {\n              await blocks.put(file.block0);\n            });\n            file.isMetadataChanged = false;\n          } catch (e) {\n            console.error(e);\n            return VFS.SQLITE_IOERR;\n          }\n        }\n        return VFS.SQLITE_OK;\n\n      case 22: // SQLITE_FCNTL_COMMIT_PHASETWO\n        // This is called after a commit is completed.\n        file.overwrite = false;\n        return VFS.SQLITE_OK;\n\n      case 31: // SQLITE_FCNTL_BEGIN_ATOMIC_WRITE\n        return this.handleAsync(async () => {\n          try {\n            // Prepare a new version for IndexedDB blocks.\n            file.block0.version--;\n            file.changedPages = new Set();\n\n            // Clear blocks from abandoned transactions that would conflict\n            // with the new transaction.\n            this.#idb.run('readwrite', async ({blocks}) => {\n              const keys = await blocks.index('version').getAllKeys(IDBKeyRange.bound(\n                [file.path],\n                [file.path, file.block0.version]));\n              for (const key of keys) {\n                blocks.delete(key);\n              }\n            });\n            return VFS.SQLITE_OK;\n          } catch (e) {\n            console.error(e);\n            return VFS.SQLITE_IOERR;\n          }\n        });\n\n      case 32: // SQLITE_FCNTL_COMMIT_ATOMIC_WRITE\n        try {\n          const block0 = Object.assign({}, file.block0);\n          block0.data = block0.data.slice();\n          const changedPages = file.changedPages;\n          file.changedPages = null;\n          file.isMetadataChanged = false;\n          this.#idb.run('readwrite', async ({blocks})=> {\n            // Write block 0 to commit the new version.\n            blocks.put(block0);\n\n            // Blocks to purge are saved in a special IndexedDB object with\n            // an \"index\" of \"purge\". Add pages changed by this transaction.\n            const purgeBlock = await blocks.get([file.path, 'purge', 0]) ?? {\n              path: file.path,\n              offset: 'purge',\n              version: 0,\n              data: new Map(),\n              count: 0\n            };\n\n            purgeBlock.count += changedPages.size;\n            for (const pageIndex of changedPages) {\n              purgeBlock.data.set(pageIndex, block0.version);\n            }\n\n            blocks.put(purgeBlock);\n            this.#maybePurge(file.path, purgeBlock.count);\n          });\n          return VFS.SQLITE_OK;\n        } catch (e) {\n          console.error(e);\n          return VFS.SQLITE_IOERR;\n        }\n\n      case 33: // SQLITE_FCNTL_ROLLBACK_ATOMIC_WRITE\n        return this.handleAsync(async () => {\n          try {\n            // Restore original state. Objects for the abandoned version will\n            // be left in IndexedDB to be removed by the next atomic write\n            // transaction.\n            file.changedPages = null;\n            file.isMetadataChanged = false;\n            file.block0 = await this.#idb.run('readonly', ({blocks}) => {\n              return blocks.get([file.path, 0, file.block0.version + 1]);\n            });\n            return VFS.SQLITE_OK;\n          } catch (e) {\n            console.error(e);\n            return VFS.SQLITE_IOERR;\n          }\n        });\n\n      default:\n        return VFS.SQLITE_NOTFOUND;\n    }\n  }\n\n  /**\n   * @param {string} name \n   * @param {number} flags \n   * @param {DataView} pResOut \n   * @returns {number}\n   */\n  xAccess(name, flags, pResOut) {\n    const result = this.handleAsync(async () => {\n      try {\n        const path = new URL(name, 'file://localhost/').pathname;\n        log(`xAccess ${path} ${flags}`);\n\n        // Check if block 0 exists.\n        const key = await this.#idb.run('readonly', ({blocks}) => {\n          return blocks.getKey(this.#bound({path}, 0));\n        });\n\n        // @ts-ignore\n        if (pResOut.buffer.detached || !pResOut.buffer.byteLength) {\n          pResOut = new DataView(new ArrayBuffer(4));\n          this.#growthHandler = (pResOutNew) => {\n            pResOutNew.setInt32(0, pResOut.getInt32(0, true), true);\n          }\n        }\n        pResOut.setInt32(0, key ? 1 : 0, true);\n        return VFS.SQLITE_OK;\n      } catch (e) {\n        console.error(e);\n        return VFS.SQLITE_IOERR;\n      }\n    });\n\n    this.#growthHandler?.(pResOut);\n    this.#growthHandler = null;\n    return result;\n  }\n\n  /**\n   * @param {string} name \n   * @param {number} syncDir \n   * @returns {number}\n   */\n  xDelete(name, syncDir) {\n    return this.handleAsync(async () => {\n      const path = new URL(name, 'file://localhost/').pathname;\n      log(`xDelete ${path} ${syncDir}`);\n\n      try {\n        this.#idb.run('readwrite', ({blocks}) => {\n          return blocks.delete(IDBKeyRange.bound([path], [path, []]));\n        });\n        if (syncDir) {\n          await this.#idb.sync();\n        }\n        return VFS.SQLITE_OK;\n      } catch (e) {\n        console.error(e);\n        return VFS.SQLITE_IOERR;\n      }\n    });\n  }\n\n  /**\n   * Purge obsolete blocks from a database file.\n   * @param {string} path \n   */\n  async purge(path) {\n    const start = Date.now();\n    await this.#idb.run('readwrite', async ({blocks}) => {\n      const purgeBlock = await blocks.get([path, 'purge', 0]);\n      if (purgeBlock) {\n        for (const [pageOffset, version] of purgeBlock.data) {\n          blocks.delete(IDBKeyRange.bound(\n            [path, pageOffset, version],\n            [path, pageOffset, Infinity],\n            true, false));\n        }\n        await blocks.delete([path, 'purge', 0]);\n      }\n      log(`purge ${path} ${purgeBlock?.data.size ?? 0} pages in ${Date.now() - start} ms`);\n    });\n  }\n\n  /**\n   * Conditionally schedule a purge task.\n   * @param {string} path \n   * @param {number} nPages \n   */\n  #maybePurge(path, nPages) {\n    if (this.#options.purge === 'manual' ||\n        this.#pendingPurges.has(path) ||\n        nPages < this.#options.purgeAtLeast) {\n      // No purge needed.\n      return;\n    }\n    \n    if (globalThis.requestIdleCallback) {\n      globalThis.requestIdleCallback(() => {\n        this.purge(path);\n        this.#pendingPurges.delete(path)\n      });\n    } else {\n      setTimeout(() => {\n        this.purge(path);\n        this.#pendingPurges.delete(path)\n      });\n    }\n    this.#pendingPurges.add(path);\n  }\n\n  #bound(file, begin, end = 0) {\n    // Fetch newest block 0. For other blocks, use block 0 version.\n    const version = !begin || -begin < file.block0.data.length ?\n      -Infinity :\n      file.block0.version;\n    return IDBKeyRange.bound(\n      [file.path, begin, version],\n      [file.path, end, Infinity]);\n  }\n\n  // The database page size can be changed with PRAGMA page_size and VACUUM.\n  // The updated file will be overwritten with a regular transaction using\n  // the old page size. After that it will be read and written using the\n  // new page size, so the IndexedDB objects must be combined or split\n  // appropriately.\n  async #reblockIfNeeded(file) {\n    const oldPageSize = file.block0.data.length;\n    if (oldPageSize < 18) return; // no page size defined\n\n    const view = new DataView(file.block0.data.buffer, file.block0.data.byteOffset);\n    let newPageSize = view.getUint16(16);\n    if (newPageSize === 1) newPageSize = 65536;\n    if (newPageSize === oldPageSize) return; // no page size change\n\n    const maxPageSize = Math.max(oldPageSize, newPageSize);\n    const nOldPages = maxPageSize / oldPageSize;\n    const nNewPages = maxPageSize / newPageSize;\n\n    const newPageCount = view.getUint32(28);\n    const fileSize = newPageCount * newPageSize;\n\n    const version = file.block0.version;\n    await this.#idb.run('readwrite', async ({blocks}) => {\n      // When the block size changes, the entire file is rewritten. Delete\n      // all blocks older than block 0 to leave a single version at every\n      // offset.\n      const keys = await blocks.index('version').getAllKeys(IDBKeyRange.bound(\n        [file.path, version + 1],\n        [file.path, Infinity]\n      ));\n      for (const key of keys) {\n        blocks.delete(key);\n      }\n      blocks.delete([file.path, 'purge', 0]);\n\n      // Do the conversion in chunks of the larger of the page sizes.\n      for (let iOffset = 0; iOffset < fileSize; iOffset += maxPageSize) {\n        // Fetch nOldPages. They can be fetched in one request because\n        // there is now a single version in the file.\n        const oldPages = await blocks.getAll(\n          IDBKeyRange.lowerBound([file.path, -(iOffset + maxPageSize), Infinity]),\n          nOldPages);\n        for (const oldPage of oldPages) {\n          blocks.delete([oldPage.path, oldPage.offset, oldPage.version]);\n        }\n\n        // Convert to new pages.\n        if (nNewPages === 1) {\n          // Combine nOldPages old pages into a new page.\n          const buffer = new Uint8Array(newPageSize);\n          for (const oldPage of oldPages) {\n            buffer.set(oldPage.data, -(iOffset + oldPage.offset));\n          }\n          const newPage = {\n            path: file.path,\n            offset: -iOffset,\n            version,\n            data: buffer\n          };\n          if (newPage.offset === 0) {\n            newPage.fileSize = fileSize;\n            file.block0 = newPage;\n          }\n          blocks.put(newPage);\n        } else {\n          // Split an old page into nNewPages new pages.\n          const oldPage = oldPages[0];\n          for (let i = 0; i < nNewPages; ++i) {\n            const offset = -(iOffset + i * newPageSize);\n            if (-offset >= fileSize) break;\n            const newPage = {\n              path: oldPage.path,\n              offset,\n              version,\n              data: oldPage.data.subarray(i * newPageSize, (i + 1) * newPageSize)\n            }\n            if (newPage.offset === 0) {\n              newPage.fileSize = fileSize;\n              file.block0 = newPage;\n            }\n            blocks.put(newPage);\n          }\n        }\n      }\n    });\n  }\n}\n\nfunction openDatabase(idbDatabaseName) {\n  return new Promise((resolve, reject) => {\n    const request = globalThis.indexedDB.open(idbDatabaseName, 5);\n    request.addEventListener('upgradeneeded', function() {\n      const blocks = request.result.createObjectStore('blocks', {\n        keyPath: ['path', 'offset', 'version']\n      });\n      blocks.createIndex('version', ['path', 'version']);\n    });\n    request.addEventListener('success', () => {\n      resolve(request.result);\n    });\n    request.addEventListener('error', () => {\n      reject(request.error);\n    });\n  });\n}","// Copyright 2022 Roy T. Hashimoto. All Rights Reserved.\n\n// IndexedDB transactions older than this will be replaced.\nconst MAX_TRANSACTION_LIFETIME_MILLIS = 5_000;\n\n// For debugging.\nlet nextTxId = 0;\nconst mapTxToId = new WeakMap();\nfunction log(...args) {\n  // console.debug(...args);\n}\n\n// This class manages IDBTransaction and IDBRequest instances. It tries\n// to reuse transactions to minimize transaction overhead.\nexport class IDBContext {\n  /** @type {IDBDatabase} */ #db;\n  /** @type {Promise<IDBDatabase>} */ #dbReady;\n  #txOptions;\n\n  /** @type {IDBTransaction} */ #tx = null;\n  #txTimestamp = 0;\n  #runChain = Promise.resolve();\n  #putChain = Promise.resolve();\n\n  /**\n   * @param {IDBDatabase|Promise<IDBDatabase>} idbDatabase\n   */\n  constructor(idbDatabase, txOptions = { durability: 'default' }) {\n    this.#dbReady = Promise.resolve(idbDatabase).then(db => this.#db = db);\n    this.#txOptions = txOptions;\n  }\n\n  async close() {\n    const db = this.#db ?? await this.#dbReady;\n    await this.#runChain;\n    await this.sync();\n    db.close();\n  }\n  \n  /**\n   * Run a function with the provided object stores. The function\n   * should be idempotent in case it is passed an expired transaction.\n   * @param {IDBTransactionMode} mode\n   * @param {(stores: Object.<string, ObjectStore>) => any} f \n   */\n  async run(mode, f) {\n    // Ensure that functions run sequentially.\n    const result = this.#runChain.then(() => this.#run(mode, f));\n    this.#runChain = result.catch(() => {});\n    return result;\n  }\n\n  /**\n   * @param {IDBTransactionMode} mode\n   * @param {(stores: Object.<string, ObjectStore>) => any} f \n   * @returns \n   */\n  async #run(mode, f) {\n    const db = this.#db ?? await this.#dbReady;\n    if (mode === 'readwrite' && this.#tx?.mode === 'readonly') {\n      // Mode requires a new transaction.\n      this.#tx = null;\n    } else if (performance.now() - this.#txTimestamp > MAX_TRANSACTION_LIFETIME_MILLIS) {\n      // Chrome times out transactions after 60 seconds so refresh preemptively.\n      try {\n        this.#tx?.commit();\n      } catch (e) {\n        // Explicit commit can fail but this can be ignored if it will\n        // auto-commit anyway.\n        if (e.name !== 'InvalidStateError') throw e;\n      }\n\n      // Skip to the next task to allow processing.\n      await new Promise(resolve => setTimeout(resolve));\n      this.#tx = null;\n    }\n\n    // Run the user function with a retry in case the transaction is invalid.\n    for (let i = 0; i < 2; ++i) {\n      if (!this.#tx) {\n        // @ts-ignore\n        this.#tx = db.transaction(db.objectStoreNames, mode, this.#txOptions);\n        const timestamp = this.#txTimestamp = performance.now();\n\n        // Chain the result of every transaction. If any transaction is\n        // aborted then the next sync() call will throw.\n        this.#putChain = this.#putChain.then(() => {\n          return new Promise((resolve, reject) => {\n            this.#tx.addEventListener('complete', event => {\n              resolve();\n              if (this.#tx === event.target) {\n                this.#tx = null;\n              }\n              log(`transaction ${mapTxToId.get(event.target)} complete`);\n            });\n            this.#tx.addEventListener('abort', event => {\n              console.warn('tx abort', (performance.now() - timestamp)/1000);\n              // @ts-ignore\n              const e = event.target.error;\n              reject(e);\n              if (this.#tx === event.target) {\n                this.#tx = null;\n              }\n              log(`transaction ${mapTxToId.get(event.target)} aborted`, e);\n            });\n          });\n        });\n\n        log(`new transaction ${nextTxId} ${mode}`);\n        mapTxToId.set(this.#tx, nextTxId++);\n      }\n\n      try {\n        const stores = Object.fromEntries(Array.from(db.objectStoreNames, name => {\n          return [name, new ObjectStore(this.#tx.objectStore(name))];\n        }));\n        return await f(stores);\n      } catch (e) {\n        this.#tx = null;\n        if (i) throw e;\n        // console.warn('retrying with new transaction');\n      }\n    }\n  }\n\n  async sync() {\n    // Wait until all transactions since the previous sync have committed.\n    // Throw if any transaction failed.\n    await this.#runChain;\n    await this.#putChain;\n    this.#putChain = Promise.resolve();\n  }\n}\n\n/**\n * Helper to convert IDBRequest to Promise.\n * @param {IDBRequest} request \n * @returns {Promise}\n */\nfunction wrapRequest(request) {\n  return new Promise((resolve, reject) => {\n    request.addEventListener('success', () => resolve(request.result));\n    request.addEventListener('error', () => reject(request.error));\n  });\n}\n\n// IDBObjectStore wrapper passed to IDBContext run functions.\nclass ObjectStore {\n  #objectStore;\n\n  /**\n   * @param {IDBObjectStore} objectStore \n   */\n  constructor(objectStore) {\n    this.#objectStore = objectStore;\n  }\n\n  /**\n   * @param {IDBValidKey|IDBKeyRange} query \n   * @returns {Promise}\n   */\n  get(query) {\n    log(`get ${this.#objectStore.name}`, query);\n    const request = this.#objectStore.get(query);\n    return wrapRequest(request);\n  }\n\n  /**\n   * @param {IDBValidKey|IDBKeyRange} query \n   * @param {number} [count]\n   * @returns {Promise}\n   */\n   getAll(query, count) {\n    log(`getAll ${this.#objectStore.name}`, query, count);\n    const request = this.#objectStore.getAll(query, count);\n    return wrapRequest(request);\n  }\n\n  /**\n   * @param {IDBValidKey|IDBKeyRange} query \n   * @returns {Promise<IDBValidKey>}\n   */\n  getKey(query) {\n    log(`getKey ${this.#objectStore.name}`, query);\n    const request = this.#objectStore.getKey(query);\n    return wrapRequest(request);\n  }\n\n  /**\n   * @param {IDBValidKey|IDBKeyRange} query \n   * @param {number} [count]\n   * @returns {Promise}\n   */\n   getAllKeys(query, count) {\n    log(`getAllKeys ${this.#objectStore.name}`, query, count);\n    const request = this.#objectStore.getAllKeys(query, count);\n    return wrapRequest(request);\n  }\n\n  /**\n   * @param {any} value\n   * @param {IDBValidKey} [key] \n   * @returns {Promise}\n   */\n   put(value, key) {\n    log(`put ${this.#objectStore.name}`, value, key);\n    const request = this.#objectStore.put(value, key);\n    return wrapRequest(request);\n  }\n\n  /**\n   * @param {IDBValidKey|IDBKeyRange} query \n   * @returns {Promise}\n   */\n   delete(query) {\n    log(`delete ${this.#objectStore.name}`, query);\n    const request = this.#objectStore.delete(query);\n    return wrapRequest(request);\n  }\n\n  clear() {\n    log(`clear ${this.#objectStore.name}`);\n    const request = this.#objectStore.clear();\n    return wrapRequest(request);\n  }\n\n  index(name) {\n    return new Index(this.#objectStore.index(name));\n  }\n}\n\nclass Index {\n  /** @type {IDBIndex} */ #index;\n\n  /**\n   * @param {IDBIndex} index \n   */\n   constructor(index) {\n    this.#index = index;\n  }\n\n  /**\n   * @param {IDBValidKey|IDBKeyRange} query \n   * @param {number} [count]\n   * @returns {Promise<IDBValidKey[]>}\n   */\n  getAllKeys(query, count) {\n    log(`IDBIndex.getAllKeys ${this.#index.objectStore.name}<${this.#index.name}>`, query, count);\n    const request = this.#index.getAllKeys(query, count);\n    return wrapRequest(request);\n  }\n}","// Copyright 2022 Roy T. Hashimoto. All Rights Reserved.\nimport * as VFS from '../VFS.js';\n\nconst LOCK_TYPE_MASK =\n  VFS.SQLITE_LOCK_NONE |\n  VFS.SQLITE_LOCK_SHARED |\n  VFS.SQLITE_LOCK_RESERVED |\n  VFS.SQLITE_LOCK_PENDING |\n  VFS.SQLITE_LOCK_EXCLUSIVE;\n\nexport class WebLocksBase {\n  get state() { return this.#state; }\n  #state = VFS.SQLITE_LOCK_NONE;\n\n  timeoutMillis = 0;\n\n  /** @type {Map<string, (value: any) => void>} */ #releasers = new Map();\n  /** @type {Promise<0|5|3850>} */ #pending = Promise.resolve(0);\n\n  /**\n   * @param {number} flags \n   * @returns {Promise<0|5|3850>} SQLITE_OK, SQLITE_BUSY, SQLITE_IOERR_LOCK\n   */\n  async lock(flags) {\n    return this.#apply(this.#lock, flags);\n  }\n\n  /**\n   * @param {number} flags \n   * @returns {Promise<0|5|3850>} SQLITE_OK, SQLITE_IOERR_LOCK\n   */\n  async unlock(flags) {\n    return this.#apply(this.#unlock, flags);\n  }\n\n  /**\n   * @returns {Promise<boolean>}\n   */\n  async isSomewhereReserved() {\n    throw new Error('unimplemented');\n  }\n\n  /**\n   * \n   * @param {(targetState: number) => void} method \n   * @param {number} flags \n   */\n  async #apply(method, flags) {\n    const targetState = flags & LOCK_TYPE_MASK;\n    try {\n      // Force locks and unlocks to run sequentially. This allows not\n      // waiting for unlocks to complete.\n      const call = () => method.call(this, targetState);\n      await (this.#pending = this.#pending.then(call, call));\n      this.#state = targetState;\n      return VFS.SQLITE_OK;\n    } catch (e) {\n      if (e.name === 'AbortError') {\n        return VFS.SQLITE_BUSY;\n      }\n      console.error(e);\n      return VFS.SQLITE_IOERR_LOCK;\n    }\n  }\n\n  async #lock(targetState) {\n    if (targetState === this.#state) return VFS.SQLITE_OK;\n    switch (this.#state) {\n      case VFS.SQLITE_LOCK_NONE:\n        switch (targetState) {\n          case VFS.SQLITE_LOCK_SHARED:\n            return this._NONEtoSHARED();\n          default:\n            throw new Error(`unexpected transition ${this.#state} -> ${targetState}`);\n        }\n\n      case VFS.SQLITE_LOCK_SHARED:\n        switch (targetState) {\n          case VFS.SQLITE_LOCK_RESERVED:\n            return this._SHAREDtoRESERVED();\n          case VFS.SQLITE_LOCK_EXCLUSIVE:\n            return this._SHAREDtoEXCLUSIVE();\n          default:\n            throw new Error(`unexpected transition ${this.#state} -> ${targetState}`);\n        }\n      \n      case VFS.SQLITE_LOCK_RESERVED:\n        switch (targetState) {\n          case VFS.SQLITE_LOCK_EXCLUSIVE:\n            return this._RESERVEDtoEXCLUSIVE();\n          default:\n            throw new Error(`unexpected transition ${this.#state} -> ${targetState}`);\n        }\n\n      default:\n        throw new Error(`unexpected transition ${this.#state} -> ${targetState}`);\n    }\n  }\n\n  async #unlock(targetState) {\n    if (targetState === this.#state)  return VFS.SQLITE_OK;\n    switch (this.#state) {\n      case VFS.SQLITE_LOCK_EXCLUSIVE:\n        switch (targetState) {\n          case VFS.SQLITE_LOCK_SHARED:\n            return this._EXCLUSIVEtoSHARED();\n          case VFS.SQLITE_LOCK_NONE:\n            return this._EXCLUSIVEtoNONE();\n          default:\n            throw new Error(`unexpected transition ${this.#state} -> ${targetState}`);\n        }\n      \n      case VFS.SQLITE_LOCK_RESERVED:\n        switch (targetState) {\n          case VFS.SQLITE_LOCK_SHARED:\n            return this._RESERVEDtoSHARED();\n          case VFS.SQLITE_LOCK_NONE:\n            return this._RESERVEDtoNONE();\n          default:\n            throw new Error(`unexpected transition ${this.#state} -> ${targetState}`);\n        }\n\n      case VFS.SQLITE_LOCK_SHARED:\n        switch (targetState) {\n          case VFS.SQLITE_LOCK_NONE:\n            return this._SHAREDtoNONE();\n          default:\n            throw new Error(`unexpected transition ${this.#state} -> ${targetState}`);\n        }\n\n      default:\n        throw new Error(`unexpected transition ${this.#state} -> ${targetState}`);\n    }\n  }\n\n  async _NONEtoSHARED() {\n  }\n\n  async _SHAREDtoEXCLUSIVE() {\n    await this._SHAREDtoRESERVED();\n    await this._RESERVEDtoEXCLUSIVE();\n  }\n\n  async _SHAREDtoRESERVED() {\n  }\n\n  async _RESERVEDtoEXCLUSIVE() {\n  }\n\n  async _EXCLUSIVEtoRESERVED() {\n  }\n\n  async _EXCLUSIVEtoSHARED() {\n    await this._EXCLUSIVEtoRESERVED();\n    await this._RESERVEDtoSHARED();\n  }\n\n  async _EXCLUSIVEtoNONE() {\n    await this._EXCLUSIVEtoRESERVED();\n    await this._RESERVEDtoSHARED();\n    await this._SHAREDtoNONE();\n  }\n\n  async _RESERVEDtoSHARED() {\n  }\n\n  async _RESERVEDtoNONE() {\n    await this._RESERVEDtoSHARED();\n    await this._SHAREDtoNONE();\n  }\n\n  async _SHAREDtoNONE() {\n  }\n\n  /**\n   * @param {string} lockName \n   * @param {LockOptions} options \n   * @returns {Promise<?Lock>}\n   */\n  _acquireWebLock(lockName, options) {\n    return new Promise(async (resolve, reject) => {\n      try {\n        await navigator.locks.request(lockName, options, lock => {\n          resolve(lock);\n          if (lock) {\n            return new Promise(release => this.#releasers.set(lockName, release));\n          }\n        });\n      } catch(e) {\n        reject(e);\n      }\n    });\n  }\n\n  /**\n   * @param {string} lockName \n   */\n  _releaseWebLock(lockName) {\n    this.#releasers.get(lockName)?.();\n    this.#releasers.delete(lockName);\n  }\n\n  /**\n   * @param {string} lockName \n   */\n  async _pollWebLock(lockName) {\n    const query = await navigator.locks.query();\n    return query.held.find(({name}) => name === lockName)?.mode;\n  }\n\n  /**\n   * @returns {?AbortSignal}\n   */\n  _getTimeoutSignal() {\n    if (this.timeoutMillis) {\n      const abortController = new AbortController();\n      setTimeout(() => abortController.abort(), this.timeoutMillis);\n      return abortController.signal;\n    }\n    return undefined;\n  }\n}\n\nexport class WebLocksExclusive extends WebLocksBase {\n  /**\n   * @param {string} name \n   */\n  constructor(name) {\n    super();\n    this._lockName = name + '-outer';\n    this._reservedName = name + '-reserved';\n  }\n\n  async isSomewhereReserved() {\n    const mode = await this._pollWebLock(this._reservedName);\n    return mode === 'exclusive';\n  }\n\n  async _NONEtoSHARED() {\n    await this._acquireWebLock(this._lockName, {\n      mode: 'exclusive',\n      signal: this._getTimeoutSignal()\n    });\n  }\n\n  async _SHAREDtoRESERVED() {\n    await this._acquireWebLock(this._reservedName, {\n      mode: 'exclusive',\n      signal: this._getTimeoutSignal()\n    });\n  }\n\n  async _RESERVEDtoSHARED() {\n    this._releaseWebLock(this._reservedName);\n  }\n\n  async _SHAREDtoNONE() {\n    this._releaseWebLock(this._lockName);\n  }\n}\n\nexport class WebLocksShared extends WebLocksBase {\n  maxRetryMillis = 1000;\n\n  /**\n   * @param {string} name \n   */\n  constructor(name) {\n    super();\n    this._outerName = name + '-outer';\n    this._innerName = name + '-inner';\n  }\n\n  async isSomewhereReserved() {\n    const mode = await this._pollWebLock(this._outerName);\n    return mode === 'exclusive';\n  }\n\n  async _NONEtoSHARED() {\n    await this._acquireWebLock(this._outerName, {\n      mode: 'shared',\n      signal: this._getTimeoutSignal()\n    });\n    await this._acquireWebLock(this._innerName, {\n      mode: 'shared',\n      signal: this._getTimeoutSignal()\n    });\n    this._releaseWebLock(this._outerName);\n  }\n\n  async _SHAREDtoRESERVED() {\n    let timeoutMillis = 1;\n    while (true) {\n      // Attempt to get the outer lock without blocking.\n      const isLocked = await this._acquireWebLock(this._outerName, {\n        mode: 'exclusive',\n        ifAvailable: true\n      });\n      if (isLocked) break;\n\n      if (await this.isSomewhereReserved()) {\n        // Someone else has a reserved lock so retry cannot succeed.\n        throw new DOMException('', 'AbortError');\n      }\n\n      await new Promise(resolve => setTimeout(resolve, timeoutMillis));\n      timeoutMillis = Math.min(2 * timeoutMillis, this.maxRetryMillis);\n    }\n    this._releaseWebLock(this._innerName);\n  }\n\n  async _RESERVEDtoEXCLUSIVE() {\n    await this._acquireWebLock(this._innerName, {\n      mode: 'exclusive',\n      signal: this._getTimeoutSignal()\n    });\n  }\n\n  async _EXCLUSIVEtoRESERVED() {\n    this._releaseWebLock(this._innerName);\n  }\n\n  async _RESERVEDtoSHARED() {\n    await this._acquireWebLock(this._innerName, { mode: 'shared' });\n    this._releaseWebLock(this._outerName);\n  }\n\n  async _SHAREDtoNONE() {\n    this._releaseWebLock(this._innerName);\n  }\n}"],"names":[],"sourceRoot":""}